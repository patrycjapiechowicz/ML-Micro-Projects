{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patrycjapiechowicz/hobby-projects/blob/main/Benchmarking_Clustering_GPU_CPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCNfcZHnmf8H"
      },
      "source": [
        "## Clustering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOVvXciLmf8K"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBqmMbEDmf8M"
      },
      "outputs": [],
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB68F8PGmf8M"
      },
      "source": [
        "<a id=\"generate\"></a>\n",
        "## Generating Data\n",
        "\n",
        "We'll generate some fake data using the `make_moons` function from the `sklearn.datasets` module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKAfAYspmf8N"
      },
      "outputs": [],
      "source": [
        "import sklearn; print('Scikit-Learn Version:', sklearn.__version__)\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "X, y = make_moons(n_samples=int(1e2), noise=0.05, random_state=0)\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZLLqQq4mf8O"
      },
      "source": [
        "Let's visualize our data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbTSmwxlmf8O"
      },
      "outputs": [],
      "source": [
        "# create figure\n",
        "figure = plt.figure()\n",
        "axis = figure.add_subplot(111)\n",
        "\n",
        "axis.scatter(X[y == 0, 0], X[y == 0, 1], \n",
        "             edgecolor='black',\n",
        "             c='lightblue', marker='o', s=40, label='cluster 1')\n",
        "axis.scatter(X[y == 1, 0], X[y == 1, 1], \n",
        "             edgecolor='black',\n",
        "             c='red', marker='s', s=40, label='cluster 2')\n",
        "axis.set_title('Empirical Data Points with Labels')\n",
        "\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-hs5yJ8mf8P"
      },
      "source": [
        "<a id=\"overview\"></a>\n",
        "## Overview of K-Means and Agglomerative Clustering\n",
        "\n",
        "There exist several algorithms for partitioning data into partitions, two of the more common of which are called K-Means and Agglomerative Clustering.\n",
        "\n",
        "The K-Means algorithm approaches the clustering problem by partitioning a set of data points into disjoint clusters, where each cluster is described by the mean of the samples in the cluster. The mean of the samples in a particular cluster is called a centroid. The K-Means algorithm finds the centroids and associates data points with centroids in such a way as to minimize the within-cluster sum-of-squares.\n",
        "\n",
        "More information on the K-Means algorithm and its implementatin in scikit-learn: http://scikit-learn.org/stable/modules/clustering.html#k-means\n",
        "\n",
        "In the code cell below, we instantiate the `KMeans` algorithm from the `sklearn.cluster` module and apply it to our data using the `fit_predict` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxtGRrPsmf8P"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rzfPp8Smf8Q"
      },
      "outputs": [],
      "source": [
        "km = KMeans(n_clusters=2, random_state=0)\n",
        "y_km = km.fit_predict(X)\n",
        "print(km.cluster_centers_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`KMeans` identifies two centroids; one located at about (-0.23, 0.56) and the other located at (1.17, -0.05)."
      ],
      "metadata": {
        "id": "8oUA7RzO8u9Z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAZkK59Kmf8Q"
      },
      "source": [
        "The Agglomerative Clustering algorithm behaves a little bit differently and does not identify clusters using centroids. Instead, it recursively merges the pair of clusters that minimally increases a given linkage distance. Put another way, the Agglomerative Clustering algorithm identifies the two data points that are \"closest\" out of all the data samples. It then takes those two data points and identifies a third data point that is \"closest\" to those two data points. The algorithm continues in this fashion for each data point; finding the next data point that is \"closest\" to the preceeding cluster of data points, where the definition of \"closest\" depends on the distance metric chosen.\n",
        "\n",
        "For more information on the Agglomerative Clustering algorithm and its implementatin in scikit-learn: http://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering\n",
        "\n",
        "Below, we instantiate the `AgglomerativeClustering` algorithm from the `sklearn.cluster` module and apply it to our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMLVTPrkmf8R"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "\n",
        "ac = AgglomerativeClustering(n_clusters=2,\n",
        "                             affinity='euclidean',\n",
        "                             linkage='complete')\n",
        "y_ac = ac.fit_predict(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwx8CdUTmf8R"
      },
      "source": [
        "We can visualize the results of both algorithms applied to the data. Visually, we see that neither algorithm ideally clusters our data. The ideal algorithm for this unique set of data would recognize that both sets of samples are generated from two different equations describing two different half circles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPZiG8Mmmf8R"
      },
      "outputs": [],
      "source": [
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 3))\n",
        "\n",
        "\n",
        "ax1.scatter(X[y_km == 0, 0], X[y_km == 0, 1],\n",
        "            edgecolor='black',\n",
        "            c='lightblue', marker='o', s=40, label='cluster 1')\n",
        "ax1.scatter(X[y_km == 1, 0], X[y_km == 1, 1],\n",
        "            edgecolor='black',\n",
        "            c='red', marker='s', s=40, label='cluster 2')\n",
        "ax1.set_title('K Means Clustering')\n",
        "\n",
        "\n",
        "ax2.scatter(X[y_ac == 0, 0], X[y_ac == 0, 1], c='lightblue',\n",
        "            edgecolor='black',\n",
        "            marker='o', s=40, label='cluster 1')\n",
        "ax2.scatter(X[y_ac == 1, 0], X[y_ac == 1, 1], c='red',\n",
        "            edgecolor='black',\n",
        "            marker='s', s=40, label='cluster 2')\n",
        "ax2.set_title('Agglomerative Clustering')\n",
        "\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKtRr_85mf8S"
      },
      "source": [
        "<a id=\"dbscan\"></a>\n",
        "## Clustering using DBSCAN\n",
        "\n",
        "Unlike K Means or Agglomerative Clustering, DBSCAN is a density-based approach to spatial clustering. It views clusters as areas of high density separated by areas of low density. This approach has several advantages; whereas K Means focuses on finding centroids and assoicating data points with that centroid in a spherical manner, the DBSCAN algorithm can identify clusters of any convex shape. Additionally, DBSCAN is robust to areas of low density. In the above visualization, we see that Agglomerative Clustering ignores the low density space space between the interleaving circles and instead focuses on finding a clustering hierarchy that minimizes the Euclidean distance. While minimizing Euclidean distance is important for some clustering problems, it is visually apparent to a human that following the density trail of points results in the ideal clustering. \n",
        "\n",
        "For more information on the DBSCAN algorithm and its implementation in scikit-learn: http://scikit-learn.org/stable/modules/clustering.html#dbscan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vZ3jdEDmf8S"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPDXxNtrmf8S"
      },
      "outputs": [],
      "source": [
        "db = DBSCAN(eps=0.2, min_samples=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mo_pdonSmf8T"
      },
      "outputs": [],
      "source": [
        "y_db = db.fit_predict(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LX1n2v-kmf8T"
      },
      "source": [
        "We see that the DBSCAN algorithm correctly identifies which half-circle each data point is generated from."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9JZV0Q5mf8T"
      },
      "outputs": [],
      "source": [
        "plt.scatter(X[y_db == 0, 0], X[y_db == 0, 1],\n",
        "            c='lightblue', marker='o', s=40,\n",
        "            edgecolor='black', \n",
        "            label='cluster 1')\n",
        "plt.scatter(X[y_db == 1, 0], X[y_db == 1, 1],\n",
        "            c='red', marker='s', s=40,\n",
        "            edgecolor='black', \n",
        "            label='cluster 2')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPLLoYG7mf8U"
      },
      "source": [
        "<a id=\"accelerating\"></a>\n",
        "## Accelerating Clustering with RAPIDS\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rapids"
      ],
      "metadata": {
        "id": "oXFd-a8n9iRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install cuml-cu11 --extra-index-url=https://pypi.ngc.nvidia.com"
      ],
      "metadata": {
        "id": "ocjX3RPO_oEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cudf-cu11 --extra-index-url=https://pypi.ngc.nvidia.com\n",
        "!rm -rf /usr/local/lib/python3.8/dist-packages/cupy*\n",
        "!pip install cupy-cuda11x"
      ],
      "metadata": {
        "id": "42At6mqF-Ovn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anwJITmjmf8U"
      },
      "outputs": [],
      "source": [
        "import cudf; print('cuDF Version:', cudf.__version__)\n",
        "import pandas as pd; print('Pandas Version:', pd.__version__)\n",
        "import cuml; print('cuML Version:', cuml.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWQenBxjmf8U"
      },
      "outputs": [],
      "source": [
        "X_df = pd.DataFrame({'fea%d'%i: X[:, i] for i in range(X.shape[1])})\n",
        "X_gdf = cudf.DataFrame.from_pandas(X_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcTu2od0mf8V"
      },
      "source": [
        "<a id=\"gpukmeans\"></a>\n",
        "## Clustering using GPU Accelerated K-Means\n",
        "\n",
        "Next, we load the `KMeans` class from the `cuml` package and instantiate it in the same way we did with the `sklearn.cluster.KMeans` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1sQD0xnmf8V"
      },
      "outputs": [],
      "source": [
        "from cuml.cluster import KMeans as KMeans_GPU\n",
        "km_gpu = KMeans_GPU(n_clusters=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CI3ZH0IDmf8V"
      },
      "outputs": [],
      "source": [
        "y_km_gpu = km_gpu.fit_predict(X_gdf).to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHXRBOaLmf8V"
      },
      "outputs": [],
      "source": [
        "plt.scatter(X[y_km_gpu == 0, 0], X[y_km_gpu == 0, 1],\n",
        "            c='lightblue', marker='o', s=40,\n",
        "            edgecolor='black', \n",
        "            label='cluster 1')\n",
        "plt.scatter(X[y_km_gpu == 1, 0], X[y_km_gpu == 1, 1],\n",
        "            c='red', marker='s', s=40,\n",
        "            edgecolor='black', \n",
        "            label='cluster 2')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SkUdN0amf8W"
      },
      "source": [
        "<a id=\"gpudbscan\"></a>\n",
        "## Clustering using GPU Accelerated DBSCAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI7K0ZZemf8W"
      },
      "source": [
        "Next, we load the `DBSCAN` class from the `cuml` package and instantiate it in the same way we did with the `sklearn.cluster.DBSCAN` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WrlSUElmf8X"
      },
      "outputs": [],
      "source": [
        "from cuml.cluster import DBSCAN as DBSCAN_GPU\n",
        "db_gpu = DBSCAN_GPU(eps=.2,min_samples = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41e6-7lXmf8X"
      },
      "outputs": [],
      "source": [
        "y_db_gpu = db_gpu.fit_predict(X_gdf).to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaCAGsPSmf8X"
      },
      "outputs": [],
      "source": [
        "plt.scatter(X[y_db_gpu == 0, 0], X[y_db_gpu == 0, 1],\n",
        "            c='lightblue', marker='o', s=40,\n",
        "            edgecolor='black', \n",
        "            label='cluster 1')\n",
        "plt.scatter(X[y_db_gpu == 1, 0], X[y_db_gpu == 1, 1],\n",
        "            c='red', marker='s', s=40,\n",
        "            edgecolor='black', \n",
        "            label='cluster 2')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNDFehbumf8Y"
      },
      "source": [
        "<a id=\"benchmarking\"></a>\n",
        "## Benchmarking: Comparing GPU and CPU\n",
        "\n",
        "RAPIDS uses GPUs to parallelize operations and accelerate computations.  \n",
        "\n",
        "The answer to this question varies depending on the size and shape of the data. As a good rule of thumb, larger datasets will benefit from RAPIDS. There is overhead associated with using a GPU; data has to be transferred from the CPU to the GPU, computations have to take place on the GPU, and the results need to be transferred back from the GPU to the CPU. However, the transactional overhead of moving data back and forth from the CPU to the GPU can quickly become negligible due to the performance speedup from computing on a GPU instead of a CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AITeJf0mmf8Z"
      },
      "outputs": [],
      "source": [
        "import numpy as np; print('NumPy Version:', np.__version__)\n",
        "\n",
        "n_rows, n_cols = 1_000_000, 128\n",
        "X = np.random.rand(n_rows, n_cols)\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WE5_9Ui_mf8Z"
      },
      "outputs": [],
      "source": [
        "X_df = pd.DataFrame({'fea%d'%i: X[:, i] for i in range(X.shape[1])})\n",
        "X_gdf = cudf.DataFrame.from_pandas(X_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-VdeJQ7mf8Z"
      },
      "source": [
        "<a id=\"benchmarkingkmeans\"></a>\n",
        "## K-Means"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ygJiXiymf8a"
      },
      "source": [
        "<a id=\"benchmarkingkmeansgpu\"></a>\n",
        "### GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "WbrlgXy6mf8a"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LtbeEw7mf8a"
      },
      "outputs": [],
      "source": [
        "km_gpu = KMeans_GPU(n_clusters=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1OOQtrGmf8a"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "y_km_gpu = km_gpu.fit_predict(X_gdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrZEWSdAmf8b"
      },
      "source": [
        "<a id=\"benchmarkingkmeanscpu\"></a>\n",
        "### CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMDQEva8mf8b"
      },
      "outputs": [],
      "source": [
        "km = KMeans(n_clusters=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExFGXZK7mf8b"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "y_km = km.fit_predict(X_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7dIEBi9mf8c"
      },
      "source": [
        "<a id=\"benchmarkingdbscan\"></a>\n",
        "## DBSCAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0X43u0Ymf8c"
      },
      "source": [
        "<a id=\"benchmarkingdbscangpu\"></a>\n",
        "### GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMiuNUHwmf8c"
      },
      "outputs": [],
      "source": [
        "db_gpu = DBSCAN_GPU(eps=3, min_samples=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "02Y-F0TUmf8c"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "y_db_gpu = db_gpu.fit_predict(X_gdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR9PP5-Dmf8d"
      },
      "source": [
        "<a id=\"benchmarkingdbscancpu\"></a>\n",
        "### CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DMThmj8mf8d"
      },
      "outputs": [],
      "source": [
        "db = DBSCAN(eps=3, min_samples=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "nGbUxJpWmf8d"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "y_db = db.fit_predict(X_df)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}